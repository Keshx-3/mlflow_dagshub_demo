# MLflow Model Management with DAGsHub

This project explores **MLflowâ€™s experiment tracking and model registry** with an **end-to-end workflow** on **DAGsHub**. It demonstrates how to manage ML experiments, track model performance, and implement a **Champion-Challenger framework**.

## ğŸ“Œ Project Overview
- **Data Generation**: Created an **imbalanced dataset** using `make_classification`.
- **Model Training**: Trained **Logistic Regression, Random Forest, XGBoost**, and **SMOTETomek-balanced XGBoost** models.
- **Experiment Tracking**: Logged **metrics, parameters, and models** in MLflow.
- **DAGsHub Integration**: Set up a **remote MLflow tracking server** on DAGsHub.
- **Model Registry**: Implemented a **Champion-Challenger model framework** for comparing models.

## ğŸ› ï¸ Technologies Used
- **Python**
- **MLflow** for experiment tracking
- **DAGsHub** for centralized MLflow tracking and collaboration
- **scikit-learn, XGBoost** for model training
- **SMOTETomek** for handling class imbalance

## ğŸš€ Why DAGsHub?
ğŸ”¹ **Version Control for Code + Data** ğŸ“  
ğŸ”¹ **Centralized Experiment Tracking with MLflow** ğŸ“Š  
ğŸ”¹ **Collaboration for ML Teams** ğŸ‘¥  

## ğŸ“‚ Repository Structure
```
â”œâ”€â”€ data/                # Synthetic dataset
â”œâ”€â”€ models/              # Saved models
â”œâ”€â”€ notebooks/           # Jupyter notebooks for experimentation
â”œâ”€â”€ src/                 # Source code for training and tracking
â”‚   â”œâ”€â”€ train.py         # Model training script
â”‚   â”œâ”€â”€ track_mlflow.py  # MLflow tracking script
â”œâ”€â”€ README.md            # Project documentation
â””â”€â”€ requirements.txt     # Required dependencies
```

## ğŸ”— Links
- **MLflow Experiment Tracking**: [DAGsHub Link]
- **Project Code**: [GitHub Link]

Would love to get feedback or contributionsâ€”feel free to check it out! ğŸš€
